{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ce4959",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyKale Tutorial: Domain Adaptation (Generalization) for Autism Detection with Multi-site Brain Imaging Data\n",
    "| [Open in Colab](https://colab.research.google.com/github/sz144/pykale/blob/brain-example/examples/autism_detection/tutorial.ipynb) (click `Runtime` → `Run all (Ctrl+F9)` |  [Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fautism_detection%2Ftutorial.ipynb) (click `Run` → `Run All Cells`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a9c14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "- Pre-processing:\n",
    "    - [Data loading](#Data-Preparation)\n",
    "    - [Construct brain networks](#Extracting-Brain-Networks-Features)\n",
    "- Machine learning pipeline:\n",
    "    - [Baseline: Ridge classifier](#Baseline)\n",
    "    - [Domain adaptation](#Domain-Adaptation)\n",
    "    - [Domain generalization](#Domain-Generalization)\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "[1] Cameron Craddock, Yassine Benhajali, Carlton Chu, Francois Chouinard, Alan Evans, András Jakab, Budhachandra Singh Khundrakpam, John David Lewis, Qingyang Li, Michael Milham, Chaogan Yan, Pierre Bellec (2013). The Neuro Bureau Preprocessing Initiative: open sharing of preprocessed neuroimaging data and derivatives. In *Neuroinformatics 2013*, Stockholm, Sweden.\n",
    "\n",
    "[2] Zhou, S., Li, W., Cox, C.R., & Lu, H. (2020). Side Information Dependence as a Regularizer for Analyzing Human Brain Conditions across Cognitive Experiments. *AAAI 2020*, New York, USA. [[Link](https://ojs.aaai.org//index.php/AAAI/article/view/6179)]\n",
    "\n",
    "[3] Zhou, S. (2022). Interpretable Domain-Aware Learning for Neuroimage Classification (Doctoral dissertation, University of Sheffield). [[Link](https://etheses.whiterose.ac.uk/31044/1/PhD_thesis_ShuoZhou_170272834.pdf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386eedc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd53bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip uninstall --yes imgaug && pip uninstall --yes albumentations && pip install git+https://github.com/aleju/imgaug.git\n",
    "    !pip install git+https://github.com/pykale/pykale.git\n",
    "    !git clone https://github.com/pykale/pykale.git\n",
    "    %cd pykale/examples/autism_detection\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a65434",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This imports required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78684d23",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn.datasets import fetch_abide_pcp\n",
    "import pandas as pd\n",
    "from config import get_cfg_defaults\n",
    "\n",
    "import sys\n",
    "\n",
    "from kale.utils.download import download_file_by_url\n",
    "from kale.interpret import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5547762",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfg_path = \"configs/tutorial.yaml\" # Path to `.yaml` config file\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "cfg.freeze()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef71fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Fetch ABIDE fMRI timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1b6cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = cfg.DATASET.ROOT\n",
    "pipeline = cfg.DATASET.PIPELINE  # fmri pre-processing pipeline\n",
    "atlas = cfg.DATASET.ATLAS\n",
    "site_ids = cfg.DATASET.SITE_IDS\n",
    "abide = fetch_abide_pcp(data_dir=root_dir, pipeline=pipeline, \n",
    "                        band_pass_filtering=True, global_signal_regression=False, \n",
    "                        derivatives=atlas, quality_checked=False,\n",
    "                        SITE_ID=site_ids, \n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d813a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read Phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb46db6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pheno_file = os.path.join(cfg.DATASET.ROOT, \"ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "pheno_info = pd.read_csv(pheno_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df053f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "View Phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871fdae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pheno_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a19241",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read timeseries from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a9afa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, \"ABIDE_pcp/%s/filt_noglobal\" % pipeline)\n",
    "use_idx = []\n",
    "time_series = []\n",
    "for i in pheno_info.index:\n",
    "    data_file_name = \"%s_%s.1D\" % (pheno_info.loc[i, \"FILE_ID\"], atlas)\n",
    "    data_path = os.path.join(data_dir, data_file_name)\n",
    "    if os.path.exists(data_path):\n",
    "        time_series.append(np.loadtxt(data_path, skiprows=0))\n",
    "        use_idx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665b774",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use \"DX_GROUP\" (autism vs control) as labels, and \"SITE_ID\" as covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d09b3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pheno = pheno_info.loc[use_idx, [\"SITE_ID\", \"DX_GROUP\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f325ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting Brain Networks Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4037a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "brain_networks = correlation_measure.fit_transform(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31d359",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Machine Learning for Multi-site Data\n",
    "\n",
    "### Cross validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df0e1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def cross_validation(x, y, covariates, estimator, domain_adaptation=False, domain_generalization=False):\n",
    "    results = {\"Target\": [], \"Num_samples\": [], \"Accuracy\": []}\n",
    "    unique_covariates = np.unique(covariates)\n",
    "    n_covariates = len(unique_covariates)\n",
    "    le = LabelEncoder()\n",
    "    covariate_mat = one_hot(torch.as_tensor(le.fit_transform(covariates)))\n",
    "    \n",
    "    for tgt in unique_covariates:\n",
    "        idx_tgt = np.where(covariates == tgt)\n",
    "        idx_src = np.where(covariates != tgt)\n",
    "        x_tgt = brain_networks[idx_tgt]\n",
    "        x_src = brain_networks[idx_src]\n",
    "        y_tgt = y[idx_tgt]\n",
    "        y_src = y[idx_src]        \n",
    "        \n",
    "        if domain_generalization:\n",
    "            estimator.fit(x_src, y_src, covariate_mat[idx_src])\n",
    "        elif domain_adaptation:\n",
    "            estimator.fit(np.concatenate((x_src, x_tgt)), y_src, \n",
    "                          np.concatenate((covariate_mat[idx_src], covariate_mat[idx_tgt])))\n",
    "        else:            \n",
    "            estimator.fit(x_src, y_src)\n",
    "        y_pred = estimator.predict(x_tgt)\n",
    "        results[\"Accuracy\"].append(accuracy_score(y_tgt, y_pred))\n",
    "        results[\"Target\"].append(tgt)\n",
    "        results[\"Num_samples\"].append(x_tgt.shape[0])\n",
    "    \n",
    "    mean_acc = sum([results[\"Num_samples\"][i] * results[\"Accuracy\"][i] for i in range(n_covariates)])\n",
    "    mean_acc /= x.shape[0]\n",
    "    results[\"Target\"].append(\"Average\")\n",
    "    results[\"Num_samples\"].append(x.shape[0])\n",
    "    results[\"Accuracy\"].append(mean_acc)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec04d89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa57354",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "estimator = RidgeClassifier()\n",
    "res_df = cross_validation(brain_networks, pheno[\"DX_GROUP\"].values, pheno[\"SITE_ID\"], estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3a33e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe6a0c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1230e54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kale.pipeline.multi_domain_adapter import _CoIRLS\n",
    "estimator = _CoIRLS(kernel=cfg.MODEL.KERNEL, lambda_=cfg.MODEL.LAMBDA_, alpha=cfg.MODEL.ALPHA)\n",
    "res_df = cross_validation(brain_networks, pheno[\"DX_GROUP\"].values, pheno[\"SITE_ID\"], \n",
    "                          estimator, domain_adaptation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49c39b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
