{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "# PyKale Tutorial: Domain Adaptation on Digits with Lightning\n",
        "\n",
        "| [Open in Colab](https://colab.research.google.com/github/pykale/pykale/blob/main/examples/digits_dann/tutorial.ipynb) (click `Runtime`\u2006\u2192\u2006`Run all (Ctrl+F9)` | [Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fdigits_dann%2Ftutorial.ipynb) (click `Run`\u2006\u2192\u2006`Run All Cells`) |\n",
        "\n",
        "If using [Google Colab](https://colab.research.google.com), a free GPU can be enabled to save time via setting `Runtime`\u2006\u2192\u2006`Change runtime type` \u2192 `Hardware accelerator: GPU`\n",
        "\n",
        "## Introduction\n",
        "\n",
        "[Domain Adaptation](https://en.wikipedia.org/wiki/Domain_adaptation) takes a model trained and evaluated on one set of data (the source) and adapts it to another (the target). In this tutorial, a model is trained on one digits dataset (source) and adapted to another (target). This tutorial is constructed based on the `digits_dann` example `main.py`, which is in turn refactored from the [ADA: (Yet) Another Domain Adaptation library](https://github.com/criteo-research/pytorch-ada). It has been put together to run interactively on online hosting platforms including [Google Colab](https://colab.research.google.com) or [myBinder](https://mybinder.org), but can also be downloaded and run locally. Follow the [PyKale installation instructions](https://pykale.readthedocs.io/en/latest/installation.html) for this."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
        "\n",
        "This checks if the notebook is running on Google Colab and installs required packages."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    !pip uninstall --yes imgaug && pip uninstall --yes albumentations && pip install git+https://github.com/aleju/imgaug.git\n",
        "    !pip install numpy>=2.0.0\n",
        "    !git clone https://github.com/pykale/pykale.git\n",
        "    %cd pykale\n",
        "    !pip install .[image,example] \n",
        "    %cd examples/digits_dann\n",
        "    !pip install tensorboard\n",
        "else:\n",
        "    print('Not running on CoLab')"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "This imports required modules."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from config import get_cfg_defaults\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "from model import get_model\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from kale.loaddata.image_access import DigitDataset, ImageAccess\n",
        "from kale.loaddata.multi_domain import BinaryDomainDatasets, MultiDomainAccess, MultiDomainDataset\n",
        "from kale.utils.seed import set_seed"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/shuo/anaconda3/envs/pykale/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "In this tutorial we modify the [default configuration for domain adaptation problems](https://github.com/pykale/pykale/blob/main/examples/digits_dann/config.py) with a customized [`.yaml` file for the specific application in this tutorial](https://github.com/pykale/pykale/blob/main/examples/digits_dann/configs/TUTORIAL.yaml). The configuration is summarized below the following cell."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "cfg_path = \"./configs/tutorial.yaml\" # Path to `.yaml` config file\n",
        "\n",
        "cfg = get_cfg_defaults()\n",
        "cfg.merge_from_file(cfg_path)\n",
        "cfg.freeze()\n",
        "print(cfg)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMET:\n",
            "  API_KEY: \n",
            "  ENABLE: False\n",
            "  EXPERIMENT_NAME: DigitDANN\n",
            "  PROJECT_NAME: Digit DANN\n",
            "DAN:\n",
            "  METHOD: DANN\n",
            "  RANDOM_DIM: 1024\n",
            "  USERANDOM: False\n",
            "DATASET:\n",
            "  DIMENSION: 784\n",
            "  NAME: digits\n",
            "  NUM_CLASSES: 10\n",
            "  NUM_REPEAT: 1\n",
            "  ROOT: ./data\n",
            "  SIZE_TYPE: source\n",
            "  SOURCE: mnist\n",
            "  TARGET: usps\n",
            "  VALID_SPLIT_RATIO: 0.5\n",
            "  WEIGHT_TYPE: natural\n",
            "OUTPUT:\n",
            "  OUT_DIR: outputs\n",
            "  PB_FRESH: 0\n",
            "  VERBOSE: False\n",
            "SOLVER:\n",
            "  AD_LAMBDA: True\n",
            "  AD_LR: True\n",
            "  BASE_LR: 0.001\n",
            "  INIT_LAMBDA: 1.0\n",
            "  LOG_EVERY_N_STEPS: 10\n",
            "  MAX_EPOCHS: 3\n",
            "  MIN_EPOCHS: 0\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: True\n",
            "  NUM_WORKERS: 0\n",
            "  SEED: 2025\n",
            "  TEST_BATCH_SIZE: 200\n",
            "  TRAIN_BATCH_SIZE: 150\n",
            "  TYPE: SGD\n",
            "  WEIGHT_DECAY: 0.0005\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Check if a GPU is available\n",
        "\n",
        "If a CUDA GPU is available, this should be used to accelerate the training process. The code below checks and reports on this."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using: \" + device)\n",
        "devices = 1 if device == \"cuda\" else 0"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cpu\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Select Datasets\n",
        "\n",
        "Source and target datasets are specified using `DigitDataset.get_source_target` from values in the configuration (`cfg`) above. In this tutorial, we specify a subset of classes (1, 3 and 8) to make training and testing quicker."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# source, target, num_channels = DigitDataset.get_source_target(\n",
        "#     DigitDataset(cfg.DATASET.SOURCE.upper()), DigitDataset(cfg.DATASET.TARGET.upper()), cfg.DATASET.ROOT\n",
        "# )\n",
        "#\n",
        "# class_subset = [1, 3, 8]\n",
        "#\n",
        "# dataset = BinaryDomainDatasets(\n",
        "#     source,\n",
        "#     target,\n",
        "#     config_weight_type=cfg.DATASET.WEIGHT_TYPE,\n",
        "#     config_size_type=cfg.DATASET.SIZE_TYPE,\n",
        "#     valid_split_ratio=cfg.DATASET.VALID_SPLIT_RATIO,\n",
        "#     class_ids=class_subset,\n",
        "# )\n",
        "data_src = DigitDataset(cfg.DATASET.SOURCE.upper())\n",
        "data_tgt = DigitDataset(cfg.DATASET.TARGET.upper())\n",
        "num_channels = max(DigitDataset.get_channel_numbers(data_src), DigitDataset.get_channel_numbers(data_tgt))\n",
        "data_access = MultiDomainAccess(\n",
        "    {\n",
        "        cfg.DATASET.SOURCE.upper(): DigitDataset.get_access(data_src, cfg.DATASET.ROOT)[0],\n",
        "        cfg.DATASET.TARGET.upper(): DigitDataset.get_access(data_tgt, cfg.DATASET.ROOT)[0],\n",
        "    },\n",
        "    cfg.DATASET.NUM_CLASSES,\n",
        "    return_domain_label=True,\n",
        ")\n",
        "# data_access = ImageAccess.get_multi_domain_images(\n",
        "#     \"DIGITS\",\n",
        "#     cfg.DATASET.ROOT,\n",
        "#     sub_domain_set=[cfg.DATASET.SOURCE.upper(), cfg.DATASET.TARGET.upper()],\n",
        "#     return_domain_label=True,\n",
        "# )\n",
        "dataset = MultiDomainDataset(data_access)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "cfg.DATASET.SOURCE.upper()",
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MNIST'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Set Seed\n",
        "\n",
        "Some algorithms used in model training require generation of pseudo-random numbers. Setting the seed from which these are generated ensures reproducibility."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "seed = cfg.SOLVER.SEED\n",
        "# seed_everything in pytorch_lightning did not set torch.backends.cudnn\n",
        "set_seed(seed)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Model\n",
        "\n",
        "Here, we use the previously defined configuration and dataset to set up the model we will subsequently train."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "%time model, train_params = get_model(cfg, dataset, num_channels)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.1 s, sys: 304 ms, total: 6.4 s\n",
            "Wall time: 6.21 s\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Output reports on data file use."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup Logger\n",
        "\n",
        "A Tensorboard logger is used to store output generated during model training. This information can be used to assess the effectiveness of the training and to identify problems. The output model is stored at `cfg.OUTPUT.OUT_DIR`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "tb_logger = TensorBoardLogger(cfg.OUTPUT.OUT_DIR, name=\"seed{}\".format(seed))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Checkpoint\n",
        "\n",
        "A `ModelCheckpoint` is used to save the model and some quantitative measure(s) periodically."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "checkpoint_callback = ModelCheckpoint(filename=\"{epoch}-{step}-{valid_loss:.4f}\", monitor=\"valid_loss\", mode=\"min\",)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "A `TQDMProgressBar` is used to set the progress bar. `PB_FRESH` determines at which rate (in number of batches) the progress bars get updated. Set it to ``0`` to disable the display."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "progress_bar = TQDMProgressBar(cfg.OUTPUT.PB_FRESH)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Trainer\n",
        "\n",
        "A trainer object is used to determine and store model parameters. Here, one is configured with information on how a model should be trained, and what hardware will be used."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "trainer = pl.Trainer(\n",
        "    min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
        "    callbacks=[checkpoint_callback, progress_bar],\n",
        "    logger=tb_logger,\n",
        "    accelerator=\"gpu\" if devices != 0 else \"cpu\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Output reports on available GPU and TPU resources."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Train Model\n",
        "\n",
        "Optimize model parameters using the trainer."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "%time trainer.fit(model)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Missing logger folder: outputs/seed2025\n",
            "\n",
            "  | Name              | Type                | Params | Mode \n",
            "------------------------------------------------------------------\n",
            "0 | feat              | SmallCNNFeature     | 309 K  | train\n",
            "1 | classifier        | ClassNetSmallImage  | 24.4 K | train\n",
            "2 | domain_classifier | DomainNetSmallImage | 13.3 K | train\n",
            "------------------------------------------------------------------\n",
            "347 K     Trainable params\n",
            "0         Non-trainable params\n",
            "347 K     Total params\n",
            "1.389     Total estimated model params size (MB)\n",
            "/home/shuo/anaconda3/envs/pykale/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
            "/home/shuo/anaconda3/envs/pykale/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15min 2s, sys: 0 ns, total: 15min 2s\n",
            "Wall time: 1min 15s\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Test Optimized Model\n",
        "\n",
        "Check performance of model optimized with training data against test data which was not used in training."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# test scores\n",
        "%time trainer.test()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/shuo/anaconda3/envs/pykale/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
            "Restoring states from the checkpoint path at outputs/seed2025/version_0/checkpoints/epoch=2-step=1212-valid_loss=1.5365.ckpt\n",
            "Loaded model weights from the checkpoint at outputs/seed2025/version_0/checkpoints/epoch=2-step=1212-valid_loss=1.5365.ckpt\n",
            "/home/shuo/anaconda3/envs/pykale/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "       Test metric             DataLoader 0\n",
            "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "     test_domain_acc        0.49561181434599155\n",
            "  test_domain_div_loss       1.392730712890625\n",
            "        test_loss            1.525232195854187\n",
            "     test_source_acc        0.9740084388185654\n",
            " test_source_domain_acc     0.3648945147679325\n",
            "     test_target_acc        0.8388185654008439\n",
            " test_target_domain_acc     0.6263291139240507\n",
            "     test_task_loss         0.13262920081615448\n",
            "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
            "CPU times: user 21 s, sys: 2.88 ms, total: 21 s\n",
            "Wall time: 1.76 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_source_acc': 0.9740084388185654,\n",
              "  'test_target_acc': 0.8388185654008439,\n",
              "  'test_domain_acc': 0.49561181434599155,\n",
              "  'test_source_domain_acc': 0.3648945147679325,\n",
              "  'test_target_domain_acc': 0.6263291139240507,\n",
              "  'test_loss': 1.525232195854187,\n",
              "  'test_task_loss': 0.13262920081615448,\n",
              "  'test_domain_div_loss': 1.392730712890625}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Outputs are defined as:\n",
        "\n",
        "* 'test_domain_acc': Accuracy on classifying the domain (source or target) from which data came.\n",
        "* 'test_source_acc': Accuracy on test data drawn from the source dataset.\n",
        "* 'test_target_acc': Accuracy on test data drawn from the target dataset.\n",
        "* 'test_loss': Loss function value on the test data."
      ],
      "cell_type": "markdown"
    }
  ]
}
