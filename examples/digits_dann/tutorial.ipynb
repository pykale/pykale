{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "# PyKale Tutorial: Domain Adaptation on Digits with Lightning\n",
        "\n",
        "| [Open in Colab](https://colab.research.google.com/github/pykale/pykale/blob/main/examples/digits_dann/tutorial.ipynb) (click `Runtime`\u2006\u2192\u2006`Run all (Ctrl+F9)` | [Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fdigits_dann%2Ftutorial.ipynb) (click `Run`\u2006\u2192\u2006`Run All Cells`) |\n",
        "\n",
        "If using [Google Colab](https://colab.research.google.com), a free GPU can be enabled to save time via setting `Runtime`\u2006\u2192\u2006`Change runtime type` \u2192 `Hardware accelerator: GPU`\n",
        "\n",
        "## Introduction\n",
        "\n",
        "[Domain Adaptation](https://en.wikipedia.org/wiki/Domain_adaptation) takes a model trained and evaluated on one set of data (the source) and adapts it to another (the target). In this tutorial, a model is trained on one digits dataset (source) and adapted to another (target). This tutorial is constructed based on the `digits_dann` example `main.py`, which is in turn refactored from the [ADA: (Yet) Another Domain Adaptation library](https://github.com/criteo-research/pytorch-ada). It has been put together to run interactively on online hosting platforms including [Google Colab](https://colab.research.google.com) or [myBinder](https://mybinder.org), but can also be downloaded and run locally. Follow the [PyKale installation instructions](https://pykale.readthedocs.io/en/latest/installation.html) for this."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
        "\n",
        "This checks if the notebook is running on Google Colab and installs required packages."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    !pip uninstall --yes imgaug && pip uninstall --yes albumentations && pip install git+https://github.com/aleju/imgaug.git\n",
        "    !git clone https://github.com/pykale/pykale.git\n",
        "    %cd pykale\n",
        "    !pip install .[image,example] \n",
        "    %cd examples/digits_dann\n",
        "    !pip install tensorboard\n",
        "else:\n",
        "    print('Not running on CoLab')"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "This imports required modules."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "from config import get_cfg_defaults\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "import torchvision\n",
        "\n",
        "from model import get_model\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from kale.loaddata.image_access import DigitDataset\n",
        "from kale.loaddata.multi_domain import MultiDomainDatasets\n",
        "from kale.utils.seed import set_seed"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "In this tutorial we modify the [default configuration for domain adaptation problems](https://github.com/pykale/pykale/blob/main/examples/digits_dann/config.py) with a customized [`.yaml` file for the specific application in this tutorial](https://github.com/pykale/pykale/blob/main/examples/digits_dann/configs/TUTORIAL.yaml). The configuration is summarized below the following cell."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "cfg_path = \"./configs/tutorial.yaml\" # Path to `.yaml` config file\n",
        "\n",
        "cfg = get_cfg_defaults()\n",
        "cfg.merge_from_file(cfg_path)\n",
        "cfg.freeze()\n",
        "print(cfg)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Check if a GPU is available\n",
        "\n",
        "If a CUDA GPU is available, this should be used to accelerate the training process. The code below checks and reports on this."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using: \" + device)\n",
        "devices = 1 if device == \"cuda\" else 0"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Select Datasets\n",
        "\n",
        "Source and target datasets are specified using `DigitDataset.get_source_target` from values in the configuration (`cfg`) above. In this tutorial, we specify a subset of classes (1, 3 and 8) to make training and testing quicker."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "source, target, num_channels = DigitDataset.get_source_target(\n",
        "    DigitDataset(cfg.DATASET.SOURCE.upper()), DigitDataset(cfg.DATASET.TARGET.upper()), cfg.DATASET.ROOT\n",
        ")\n",
        "\n",
        "class_subset = [1, 3, 8]\n",
        "\n",
        "dataset = MultiDomainDatasets(\n",
        "    source,\n",
        "    target,\n",
        "    config_weight_type=cfg.DATASET.WEIGHT_TYPE,\n",
        "    config_size_type=cfg.DATASET.SIZE_TYPE,\n",
        "    valid_split_ratio=cfg.DATASET.VALID_SPLIT_RATIO,\n",
        "    class_ids=class_subset,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Set Seed\n",
        "\n",
        "Some algorithms used in model training require generation of pseudo-random numbers. Setting the seed from which these are generated ensures reproducibility."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "seed = cfg.SOLVER.SEED\n",
        "# seed_everything in pytorch_lightning did not set torch.backends.cudnn\n",
        "set_seed(seed)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Model\n",
        "\n",
        "Here, we use the previously defined configuration and dataset to set up the model we will subsequently train."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "%time model, train_params = get_model(cfg, dataset, num_channels)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Output reports on data file use."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup Logger\n",
        "\n",
        "A Tensorboard logger is used to store output generated during model training. This information can be used to assess the effectiveness of the training and to identify problems. The output model is stored at `cfg.OUTPUT.TB_DIR`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "tb_logger = TensorBoardLogger(cfg.OUTPUT.OUT_DIR, name=\"seed{}\".format(seed))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Checkpoint\n",
        "\n",
        "A `ModelCheckpoint` is used to save the model and some quantitative measure(s) periodically."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "checkpoint_callback = ModelCheckpoint(filename=\"{epoch}-{step}-{valid_loss:.4f}\", monitor=\"valid_loss\", mode=\"min\",)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "A `TQDMProgressBar` is used to set the progress bar. `PB_FRESH` determines at which rate (in number of batches) the progress bars get updated. Set it to ``0`` to disable the display."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "progress_bar = TQDMProgressBar(cfg.OUTPUT.PB_FRESH)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Trainer\n",
        "\n",
        "A trainer object is used to determine and store model parameters. Here, one is configured with information on how a model should be trained, and what hardware will be used."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "trainer = pl.Trainer(\n",
        "    min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
        "    callbacks=[checkpoint_callback, progress_bar],\n",
        "    logger=tb_logger,\n",
        "    accelerator=\"gpu\" if devices != 0 else \"cpu\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Output reports on available GPU and TPU resources."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Train Model\n",
        "\n",
        "Optimize model parameters using the trainer."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "%time trainer.fit(model)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Test Optimized Model\n",
        "\n",
        "Check performance of model optimized with training data against test data which was not used in training."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# test scores\n",
        "%time trainer.test()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Outputs are defined as:\n",
        "\n",
        "* 'test_domain_acc': Accuracy on classifying the domain (source or target) from which data came.\n",
        "* 'test_source_acc': Accuracy on test data drawn from the source dataset.\n",
        "* 'test_target_acc': Accuracy on test data drawn from the target dataset.\n",
        "* 'test_loss': Loss function value on the test data."
      ],
      "cell_type": "markdown"
    }
  ]
}
